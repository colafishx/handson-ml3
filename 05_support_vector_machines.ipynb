{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/colafishx/handson-ml3/blob/main/05_support_vector_machines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luDk0ewiaRUQ"
      },
      "source": [
        "**Support Vector Machines**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TETyA58XaRUS"
      },
      "source": [
        "_This notebook contains all the sample code and solutions to the exercises in chapter 5._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIuJzHRraRUS"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/ageron/handson-ml3/blob/main/05_support_vector_machines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ageron/handson-ml3/blob/main/05_support_vector_machines.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "zkYKYEFEaRUT"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb5xz1UQaRUT"
      },
      "source": [
        "This project requires Python 3.7 or above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "igV4zZt2aRUT"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "assert sys.version_info >= (3, 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdgfTi6oaRUU"
      },
      "source": [
        "It also requires Scikit-Learn â‰¥ 1.0.1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Wp9B7MMPaRUV"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import sklearn\n",
        "\n",
        "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVQYKQIMaRUV"
      },
      "source": [
        "As we did in previous chapters, let's define the default font sizes to make the figures prettier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5C8ULzguaRUV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ9X3VpYaRUW"
      },
      "source": [
        "And let's create the `images/svm` folder (if it doesn't already exist), and define the `save_fig()` function which is used through this notebook to save the figures in high-res for the book:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KrIqNyhLaRUW"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "IMAGES_PATH = Path() / \"images\" / \"svm\"\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float(\"inf\")"
      ],
      "metadata": {
        "id": "yAuK8Sf8bUZF",
        "outputId": "907c00cb-c88a-4fd5-9286-b3ce3fd58039",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "inf"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFiRE0cKaRUW"
      },
      "source": [
        "# Linear SVM Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIL6fM6-aRUW"
      },
      "source": [
        "The book starts with a few figures, before the first code example, so the next three cells generate and save these figures. You can skip them if you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "x_2kokY0aRUW",
        "outputId": "36d6ceda-6c0e-4ba7-ddb6-431cdedd330f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x270 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# extra code â€“ this cell generates and saves Figure 5â€“1\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris(as_frame=True)\n",
        "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
        "y = iris.target\n",
        "\n",
        "setosa_or_versicolor = (y == 0) | (y == 1)\n",
        "X = X[setosa_or_versicolor]\n",
        "y = y[setosa_or_versicolor]\n",
        "\n",
        "# SVM Classifier model\n",
        "# svm_clf = SVC(kernel=\"linear\", C=float('inf'))\n",
        "svm_clf = SVC(kernel=\"linear\", C=float(99999999999999999999999999999999999999999999))\n",
        "svm_clf.fit(X, y)\n",
        "\n",
        "# Bad models\n",
        "x0 = np.linspace(0, 5.5, 200)\n",
        "pred_1 = 5 * x0 - 20\n",
        "pred_2 = x0 - 1.8\n",
        "pred_3 = 0.1 * x0 + 0.5\n",
        "\n",
        "def plot_svc_decision_boundary(svm_clf, xmin, xmax):\n",
        "    w = svm_clf.coef_[0]\n",
        "    b = svm_clf.intercept_[0]\n",
        "\n",
        "    # At the decision boundary, w0*x0 + w1*x1 + b = 0\n",
        "    # => x1 = -w0/w1 * x0 - b/w1\n",
        "    x0 = np.linspace(xmin, xmax, 200)\n",
        "    decision_boundary = -w[0] / w[1] * x0 - b / w[1]\n",
        "\n",
        "    margin = 1/w[1]\n",
        "    gutter_up = decision_boundary + margin\n",
        "    gutter_down = decision_boundary - margin\n",
        "    svs = svm_clf.support_vectors_\n",
        "\n",
        "    plt.plot(x0, decision_boundary, \"k-\", linewidth=2, zorder=-2)\n",
        "    plt.plot(x0, gutter_up, \"k--\", linewidth=2, zorder=-2)\n",
        "    plt.plot(x0, gutter_down, \"k--\", linewidth=2, zorder=-2)\n",
        "    plt.scatter(svs[:, 0], svs[:, 1], s=180, facecolors='#AAA',\n",
        "                zorder=-1)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(10, 2.7), sharey=True)\n",
        "\n",
        "plt.sca(axes[0])\n",
        "plt.plot(x0, pred_1, \"g--\", linewidth=2)\n",
        "plt.plot(x0, pred_2, \"m-\", linewidth=2)\n",
        "plt.plot(x0, pred_3, \"r-\", linewidth=2)\n",
        "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", label=\"Iris versicolor\")\n",
        "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", label=\"Iris setosa\")\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.ylabel(\"Petal width\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.axis([0, 5.5, 0, 2])\n",
        "plt.gca().set_aspect(\"equal\")\n",
        "plt.grid()\n",
        "\n",
        "plt.sca(axes[1])\n",
        "plot_svc_decision_boundary(svm_clf, 0, 5.5)\n",
        "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\")\n",
        "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\")\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.axis([0, 5.5, 0, 2])\n",
        "plt.gca().set_aspect(\"equal\")\n",
        "plt.grid()\n",
        "\n",
        "save_fig(\"large_margin_classification_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPNQme5laRUX"
      },
      "outputs": [],
      "source": [
        "# extra code â€“ this cell generates and saves Figure 5â€“2\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "Xs = np.array([[1, 50], [5, 20], [3, 80], [5, 60]]).astype(np.float64)\n",
        "ys = np.array([0, 0, 1, 1])\n",
        "svm_clf = SVC(kernel=\"linear\", C=100).fit(Xs, ys)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(Xs)\n",
        "svm_clf_scaled = SVC(kernel=\"linear\", C=100).fit(X_scaled, ys)\n",
        "\n",
        "plt.figure(figsize=(9, 2.7))\n",
        "plt.subplot(121)\n",
        "plt.plot(Xs[:, 0][ys==1], Xs[:, 1][ys==1], \"bo\")\n",
        "plt.plot(Xs[:, 0][ys==0], Xs[:, 1][ys==0], \"ms\")\n",
        "plot_svc_decision_boundary(svm_clf, 0, 6)\n",
        "plt.xlabel(\"$x_0$\")\n",
        "plt.ylabel(\"$x_1$Â Â Â Â \", rotation=0)\n",
        "plt.title(\"Unscaled\")\n",
        "plt.axis([0, 6, 0, 90])\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(X_scaled[:, 0][ys==1], X_scaled[:, 1][ys==1], \"bo\")\n",
        "plt.plot(X_scaled[:, 0][ys==0], X_scaled[:, 1][ys==0], \"ms\")\n",
        "plot_svc_decision_boundary(svm_clf_scaled, -2, 2)\n",
        "plt.xlabel(\"$x'_0$\")\n",
        "plt.ylabel(\"$x'_1$  \", rotation=0)\n",
        "plt.title(\"Scaled\")\n",
        "plt.axis([-2, 2, -2, 2])\n",
        "plt.grid()\n",
        "\n",
        "save_fig(\"sensitivity_to_feature_scales_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9aqH74iaRUX"
      },
      "source": [
        "## Soft Margin Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLr_wxcRaRUY"
      },
      "outputs": [],
      "source": [
        "# extra code â€“ this cell generates and saves Figure 5â€“3\n",
        "\n",
        "X_outliers = np.array([[3.4, 1.3], [3.2, 0.8]])\n",
        "y_outliers = np.array([0, 0])\n",
        "Xo1 = np.concatenate([X, X_outliers[:1]], axis=0)\n",
        "yo1 = np.concatenate([y, y_outliers[:1]], axis=0)\n",
        "Xo2 = np.concatenate([X, X_outliers[1:]], axis=0)\n",
        "yo2 = np.concatenate([y, y_outliers[1:]], axis=0)\n",
        "\n",
        "svm_clf2 = SVC(kernel=\"linear\", C=10**9)\n",
        "svm_clf2.fit(Xo2, yo2)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(10, 2.7), sharey=True)\n",
        "\n",
        "plt.sca(axes[0])\n",
        "plt.plot(Xo1[:, 0][yo1==1], Xo1[:, 1][yo1==1], \"bs\")\n",
        "plt.plot(Xo1[:, 0][yo1==0], Xo1[:, 1][yo1==0], \"yo\")\n",
        "plt.text(0.3, 1.0, \"Impossible!\", color=\"red\", fontsize=18)\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.ylabel(\"Petal width\")\n",
        "plt.annotate(\n",
        "    \"Outlier\",\n",
        "    xy=(X_outliers[0][0], X_outliers[0][1]),\n",
        "    xytext=(2.5, 1.7),\n",
        "    ha=\"center\",\n",
        "    arrowprops=dict(facecolor='black', shrink=0.1),\n",
        ")\n",
        "plt.axis([0, 5.5, 0, 2])\n",
        "plt.grid()\n",
        "\n",
        "plt.sca(axes[1])\n",
        "plt.plot(Xo2[:, 0][yo2==1], Xo2[:, 1][yo2==1], \"bs\")\n",
        "plt.plot(Xo2[:, 0][yo2==0], Xo2[:, 1][yo2==0], \"yo\")\n",
        "plot_svc_decision_boundary(svm_clf2, 0, 5.5)\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.annotate(\n",
        "    \"Outlier\",\n",
        "    xy=(X_outliers[1][0], X_outliers[1][1]),\n",
        "    xytext=(3.2, 0.08),\n",
        "    ha=\"center\",\n",
        "    arrowprops=dict(facecolor='black', shrink=0.1),\n",
        ")\n",
        "plt.axis([0, 5.5, 0, 2])\n",
        "plt.grid()\n",
        "\n",
        "save_fig(\"sensitivity_to_outliers_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GN9Im_wxaRUY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "iris = load_iris(as_frame=True)\n",
        "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
        "y = (iris.target == 2)  # Iris virginica\n",
        "\n",
        "svm_clf = make_pipeline(StandardScaler(),\n",
        "                        LinearSVC(C=1, random_state=42))\n",
        "svm_clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFCmNSF9aRUY"
      },
      "outputs": [],
      "source": [
        "X_new = [[5.5, 1.7], [5.0, 1.5]]\n",
        "svm_clf.predict(X_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W49ZaW2PaRUY"
      },
      "outputs": [],
      "source": [
        "svm_clf.decision_function(X_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hl6EAn-aRUY"
      },
      "outputs": [],
      "source": [
        "# extra code â€“ this cell generates and saves Figure 5â€“4\n",
        "\n",
        "scaler = StandardScaler()\n",
        "svm_clf1 = LinearSVC(C=1, max_iter=10_000, random_state=42)\n",
        "svm_clf2 = LinearSVC(C=100, max_iter=10_000, random_state=42)\n",
        "\n",
        "scaled_svm_clf1 = make_pipeline(scaler, svm_clf1)\n",
        "scaled_svm_clf2 = make_pipeline(scaler, svm_clf2)\n",
        "\n",
        "scaled_svm_clf1.fit(X, y)\n",
        "scaled_svm_clf2.fit(X, y)\n",
        "\n",
        "# Convert to unscaled parameters\n",
        "b1 = svm_clf1.decision_function([-scaler.mean_ / scaler.scale_])\n",
        "b2 = svm_clf2.decision_function([-scaler.mean_ / scaler.scale_])\n",
        "w1 = svm_clf1.coef_[0] / scaler.scale_\n",
        "w2 = svm_clf2.coef_[0] / scaler.scale_\n",
        "svm_clf1.intercept_ = np.array([b1])\n",
        "svm_clf2.intercept_ = np.array([b2])\n",
        "svm_clf1.coef_ = np.array([w1])\n",
        "svm_clf2.coef_ = np.array([w2])\n",
        "\n",
        "# Find support vectors (LinearSVC does not do this automatically)\n",
        "t = y * 2 - 1\n",
        "support_vectors_idx1 = (t * (X.dot(w1) + b1) < 1).ravel()\n",
        "support_vectors_idx2 = (t * (X.dot(w2) + b2) < 1).ravel()\n",
        "svm_clf1.support_vectors_ = X[support_vectors_idx1]\n",
        "svm_clf2.support_vectors_ = X[support_vectors_idx2]\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(10, 2.7), sharey=True)\n",
        "\n",
        "plt.sca(axes[0])\n",
        "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\", label=\"Iris virginica\")\n",
        "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bs\", label=\"Iris versicolor\")\n",
        "plot_svc_decision_boundary(svm_clf1, 4, 5.9)\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.ylabel(\"Petal width\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.title(f\"$C = {svm_clf1.C}$\")\n",
        "plt.axis([4, 5.9, 0.8, 2.8])\n",
        "plt.grid()\n",
        "\n",
        "plt.sca(axes[1])\n",
        "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\")\n",
        "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bs\")\n",
        "plot_svc_decision_boundary(svm_clf2, 4, 5.99)\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.title(f\"$C = {svm_clf2.C}$\")\n",
        "plt.axis([4, 5.9, 0.8, 2.8])\n",
        "plt.grid()\n",
        "\n",
        "save_fig(\"regularization_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eg9OpcDaRUY"
      },
      "source": [
        "# Nonlinear SVM Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqUD_LidaRUZ"
      },
      "outputs": [],
      "source": [
        "# extra code â€“ this cell generates and saves Figure 5â€“5\n",
        "\n",
        "X1D = np.linspace(-4, 4, 9).reshape(-1, 1)\n",
        "X2D = np.c_[X1D, X1D**2]\n",
        "y = np.array([0, 0, 1, 1, 1, 1, 1, 0, 0])\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.grid(True)\n",
        "plt.axhline(y=0, color='k')\n",
        "plt.plot(X1D[:, 0][y==0], np.zeros(4), \"bs\")\n",
        "plt.plot(X1D[:, 0][y==1], np.zeros(5), \"g^\")\n",
        "plt.gca().get_yaxis().set_ticks([])\n",
        "plt.xlabel(\"$x_1$\")\n",
        "plt.axis([-4.5, 4.5, -0.2, 0.2])\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.grid(True)\n",
        "plt.axhline(y=0, color='k')\n",
        "plt.axvline(x=0, color='k')\n",
        "plt.plot(X2D[:, 0][y==0], X2D[:, 1][y==0], \"bs\")\n",
        "plt.plot(X2D[:, 0][y==1], X2D[:, 1][y==1], \"g^\")\n",
        "plt.xlabel(\"$x_1$\")\n",
        "plt.ylabel(\"$x_2$Â Â \", rotation=0)\n",
        "plt.gca().get_yaxis().set_ticks([0, 4, 8, 12, 16])\n",
        "plt.plot([-4.5, 4.5], [6.5, 6.5], \"r--\", linewidth=3)\n",
        "plt.axis([-4.5, 4.5, -1, 17])\n",
        "\n",
        "plt.subplots_adjust(right=1)\n",
        "\n",
        "save_fig(\"higher_dimensions_plot\", tight_layout=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxuOS9IRaRUZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "X, y = make_moons(n_samples=100, noise=0.15, random_state=42)\n",
        "\n",
        "polynomial_svm_clf = make_pipeline(\n",
        "    PolynomialFeatures(degree=3),\n",
        "    StandardScaler(),\n",
        "    LinearSVC(C=10, max_iter=10_000, random_state=42)\n",
        ")\n",
        "polynomial_svm_clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTQrSQU2aRUZ"
      },
      "outputs": [],
      "source": [
        "# extra code â€“ this cell generates and saves Figure 5â€“6\n",
        "\n",
        "def plot_dataset(X, y, axes):\n",
        "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bs\")\n",
        "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\")\n",
        "    plt.axis(axes)\n",
        "    plt.grid(True)\n",
        "    plt.xlabel(\"$x_1$\")\n",
        "    plt.ylabel(\"$x_2$\", rotation=0)\n",
        "\n",
        "def plot_predictions(clf, axes):\n",
        "    x0s = np.linspace(axes[0], axes[1], 100)\n",
        "    x1s = np.linspace(axes[2], axes[3], 100)\n",
        "    x0, x1 = np.meshgrid(x0s, x1s)\n",
        "    X = np.c_[x0.ravel(), x1.ravel()]\n",
        "    y_pred = clf.predict(X).reshape(x0.shape)\n",
        "    y_decision = clf.decision_function(X).reshape(x0.shape)\n",
        "    plt.contourf(x0, x1, y_pred, cmap=plt.cm.brg, alpha=0.2)\n",
        "    plt.contourf(x0, x1, y_decision, cmap=plt.cm.brg, alpha=0.1)\n",
        "\n",
        "plot_predictions(polynomial_svm_clf, [-1.5, 2.5, -1, 1.5])\n",
        "plot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\n",
        "\n",
        "save_fig(\"moons_polynomial_svc_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfDWaXW0aRUZ"
      },
      "source": [
        "## Polynomial Kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5QBa4FBaRUZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "poly_kernel_svm_clf = make_pipeline(StandardScaler(),\n",
        "                                    SVC(kernel=\"poly\", degree=3, coef0=1, C=5))\n",
        "poly_kernel_svm_clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVN96hH9aRUZ"
      },
      "outputs": [],
      "source": [
        "# extra code â€“ this cell generates and saves Figure 5â€“7\n",
        "\n",
        "poly100_kernel_svm_clf = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SVC(kernel=\"poly\", degree=10, coef0=100, C=5)\n",
        ")\n",
        "poly100_kernel_svm_clf.fit(X, y)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(10.5, 4), sharey=True)\n",
        "\n",
        "plt.sca(axes[0])\n",
        "plot_predictions(poly_kernel_svm_clf, [-1.5, 2.45, -1, 1.5])\n",
        "plot_dataset(X, y, [-1.5, 2.4, -1, 1.5])\n",
        "plt.title(\"degree=3, coef0=1, C=5\")\n",
        "\n",
        "plt.sca(axes[1])\n",
        "plot_predictions(poly100_kernel_svm_clf, [-1.5, 2.45, -1, 1.5])\n",
        "plot_dataset(X, y, [-1.5, 2.4, -1, 1.5])\n",
        "plt.title(\"degree=10, coef0=100, C=5\")\n",
        "plt.ylabel(\"\")\n",
        "\n",
        "save_fig(\"moons_kernelized_polynomial_svc_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qES7dS-7aRUZ"
      },
      "source": [
        "## Similarity Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "HPSVtGYTaRUZ"
      },
      "outputs": [],
      "source": [
        "# extra code â€“ this cell generates and saves Figure 5â€“8\n",
        "\n",
        "def gaussian_rbf(x, landmark, gamma):\n",
        "    return np.exp(-gamma * np.linalg.norm(x - landmark, axis=1)**2)\n",
        "\n",
        "gamma = 0.3\n",
        "\n",
        "x1s = np.linspace(-4.5, 4.5, 200).reshape(-1, 1)\n",
        "x2s = gaussian_rbf(x1s, -2, gamma)\n",
        "x3s = gaussian_rbf(x1s, 1, gamma)\n",
        "\n",
        "XK = np.c_[gaussian_rbf(X1D, -2, gamma), gaussian_rbf(X1D, 1, gamma)]\n",
        "yk = np.array([0, 0, 1, 1, 1, 1, 1, 0, 0])\n",
        "\n",
        "plt.figure(figsize=(10.5, 4))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.grid(True)\n",
        "plt.axhline(y=0, color='k')\n",
        "plt.scatter(x=[-2, 1], y=[0, 0], s=150, alpha=0.5, c=\"red\")\n",
        "plt.plot(X1D[:, 0][yk==0], np.zeros(4), \"bs\")\n",
        "plt.plot(X1D[:, 0][yk==1], np.zeros(5), \"g^\")\n",
        "plt.plot(x1s, x2s, \"g--\")\n",
        "plt.plot(x1s, x3s, \"b:\")\n",
        "plt.gca().get_yaxis().set_ticks([0, 0.25, 0.5, 0.75, 1])\n",
        "plt.xlabel(\"$x_1$\")\n",
        "plt.ylabel(\"Similarity\")\n",
        "plt.annotate(\n",
        "    r'$\\mathbf{x}$',\n",
        "    xy=(X1D[3, 0], 0),\n",
        "    xytext=(-0.5, 0.20),\n",
        "    ha=\"center\",\n",
        "    arrowprops=dict(facecolor='black', shrink=0.1),\n",
        "    fontsize=16,\n",
        ")\n",
        "plt.text(-2, 0.9, \"$x_2$\", ha=\"center\", fontsize=15)\n",
        "plt.text(1, 0.9, \"$x_3$\", ha=\"center\", fontsize=15)\n",
        "plt.axis([-4.5, 4.5, -0.1, 1.1])\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.grid(True)\n",
        "plt.axhline(y=0, color='k')\n",
        "plt.axvline(x=0, color='k')\n",
        "plt.plot(XK[:, 0][yk==0], XK[:, 1][yk==0], \"bs\")\n",
        "plt.plot(XK[:, 0][yk==1], XK[:, 1][yk==1], \"g^\")\n",
        "plt.xlabel(\"$x_2$\")\n",
        "plt.ylabel(\"$x_3$Â Â \", rotation=0)\n",
        "plt.annotate(\n",
        "    r'$\\phi\\left(\\mathbf{x}\\right)$',\n",
        "    xy=(XK[3, 0], XK[3, 1]),\n",
        "    xytext=(0.65, 0.50),\n",
        "    ha=\"center\",\n",
        "    arrowprops=dict(facecolor='black', shrink=0.1),\n",
        "    fontsize=16,\n",
        ")\n",
        "plt.plot([-0.1, 1.1], [0.57, -0.1], \"r--\", linewidth=3)\n",
        "plt.axis([-0.1, 1.1, -0.1, 1.1])\n",
        "\n",
        "plt.subplots_adjust(right=1)\n",
        "\n",
        "save_fig(\"kernel_method_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWeR8gIcaRUa"
      },
      "source": [
        "## Gaussian RBF Kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmxFFgDWaRUa"
      },
      "outputs": [],
      "source": [
        "rbf_kernel_svm_clf = make_pipeline(StandardScaler(),\n",
        "                                   SVC(kernel=\"rbf\", gamma=5, C=0.001))\n",
        "rbf_kernel_svm_clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "PetIIoW0aRUa"
      },
      "outputs": [],
      "source": [
        "# extra code â€“ this cell generates and saves Figure 5â€“9\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "gamma1, gamma2 = 0.1, 5\n",
        "C1, C2 = 0.001, 1000\n",
        "hyperparams = (gamma1, C1), (gamma1, C2), (gamma2, C1), (gamma2, C2)\n",
        "\n",
        "svm_clfs = []\n",
        "for gamma, C in hyperparams:\n",
        "    rbf_kernel_svm_clf = make_pipeline(\n",
        "        StandardScaler(),\n",
        "        SVC(kernel=\"rbf\", gamma=gamma, C=C)\n",
        "    )\n",
        "    rbf_kernel_svm_clf.fit(X, y)\n",
        "    svm_clfs.append(rbf_kernel_svm_clf)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10.5, 7), sharex=True, sharey=True)\n",
        "\n",
        "for i, svm_clf in enumerate(svm_clfs):\n",
        "    plt.sca(axes[i // 2, i % 2])\n",
        "    plot_predictions(svm_clf, [-1.5, 2.45, -1, 1.5])\n",
        "    plot_dataset(X, y, [-1.5, 2.45, -1, 1.5])\n",
        "    gamma, C = hyperparams[i]\n",
        "    plt.title(f\"gamma={gamma}, C={C}\")\n",
        "    if i in (0, 1):\n",
        "        plt.xlabel(\"\")\n",
        "    if i in (1, 3):\n",
        "        plt.ylabel(\"\")\n",
        "\n",
        "save_fig(\"moons_rbf_svc_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e423MNNGaRUa"
      },
      "source": [
        "# SVM Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnqBkAzRaRUa"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "\n",
        "# extra code â€“ these 3 lines generate a simple linear dataset\n",
        "np.random.seed(42)\n",
        "X = 2 * np.random.rand(50, 1)\n",
        "y = 4 + 3 * X[:, 0] + np.random.randn(50)\n",
        "\n",
        "svm_reg = make_pipeline(StandardScaler(),\n",
        "                        LinearSVR(epsilon=0.5, random_state=42))\n",
        "svm_reg.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWblV_pbaRUa"
      },
      "outputs": [],
      "source": [
        "# extra code â€“ this cell generates and saves Figure 5â€“10\n",
        "\n",
        "def find_support_vectors(svm_reg, X, y):\n",
        "    y_pred = svm_reg.predict(X)\n",
        "    epsilon = svm_reg[-1].epsilon\n",
        "    off_margin = np.abs(y - y_pred) >= epsilon\n",
        "    return np.argwhere(off_margin)\n",
        "\n",
        "def plot_svm_regression(svm_reg, X, y, axes):\n",
        "    x1s = np.linspace(axes[0], axes[1], 100).reshape(100, 1)\n",
        "    y_pred = svm_reg.predict(x1s)\n",
        "    epsilon = svm_reg[-1].epsilon\n",
        "    plt.plot(x1s, y_pred, \"k-\", linewidth=2, label=r\"$\\hat{y}$\", zorder=-2)\n",
        "    plt.plot(x1s, y_pred + epsilon, \"k--\", zorder=-2)\n",
        "    plt.plot(x1s, y_pred - epsilon, \"k--\", zorder=-2)\n",
        "    plt.scatter(X[svm_reg._support], y[svm_reg._support], s=180,\n",
        "                facecolors='#AAA', zorder=-1)\n",
        "    plt.plot(X, y, \"bo\")\n",
        "    plt.xlabel(\"$x_1$\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.axis(axes)\n",
        "\n",
        "svm_reg2 = make_pipeline(StandardScaler(),\n",
        "                         LinearSVR(epsilon=1.2, random_state=42))\n",
        "svm_reg2.fit(X, y)\n",
        "\n",
        "svm_reg._support = find_support_vectors(svm_reg, X, y)\n",
        "svm_reg2._support = find_support_vectors(svm_reg2, X, y)\n",
        "\n",
        "eps_x1 = 1\n",
        "eps_y_pred = svm_reg2.predict([[eps_x1]])\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(9, 4), sharey=True)\n",
        "plt.sca(axes[0])\n",
        "plot_svm_regression(svm_reg, X, y, [0, 2, 3, 11])\n",
        "plt.title(f\"epsilon={svm_reg[-1].epsilon}\")\n",
        "plt.ylabel(\"$y$\", rotation=0)\n",
        "plt.grid()\n",
        "plt.sca(axes[1])\n",
        "plot_svm_regression(svm_reg2, X, y, [0, 2, 3, 11])\n",
        "plt.title(f\"epsilon={svm_reg2[-1].epsilon}\")\n",
        "plt.annotate(\n",
        "        '', xy=(eps_x1, eps_y_pred), xycoords='data',\n",
        "        xytext=(eps_x1, eps_y_pred - svm_reg2[-1].epsilon),\n",
        "        textcoords='data', arrowprops={'arrowstyle': '<->', 'linewidth': 1.5}\n",
        "    )\n",
        "plt.text(0.90, 5.4, r\"$\\epsilon$\", fontsize=16)\n",
        "plt.grid()\n",
        "save_fig(\"svm_regression_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk1EkNNWaRUa"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "# extra code â€“ these 3 lines generate a simple quadratic dataset\n",
        "np.random.seed(42)\n",
        "X = 2 * np.random.rand(50, 1) - 1\n",
        "y = 0.2 + 0.1 * X[:, 0] + 0.5 * X[:, 0] ** 2 + np.random.randn(50) / 10\n",
        "\n",
        "svm_poly_reg = make_pipeline(StandardScaler(),\n",
        "                             SVR(kernel=\"poly\", degree=2, C=0.01, epsilon=0.1))\n",
        "svm_poly_reg.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiEWlSO2aRUa"
      },
      "outputs": [],
      "source": [
        "# extra code â€“ this cell generates and saves Figure 5â€“11\n",
        "\n",
        "svm_poly_reg2 = make_pipeline(StandardScaler(),\n",
        "                             SVR(kernel=\"poly\", degree=2, C=100))\n",
        "svm_poly_reg2.fit(X, y)\n",
        "\n",
        "svm_poly_reg._support = find_support_vectors(svm_poly_reg, X, y)\n",
        "svm_poly_reg2._support = find_support_vectors(svm_poly_reg2, X, y)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(9, 4), sharey=True)\n",
        "plt.sca(axes[0])\n",
        "plot_svm_regression(svm_poly_reg, X, y, [-1, 1, 0, 1])\n",
        "plt.title(f\"degree={svm_poly_reg[-1].degree}, \"\n",
        "          f\"C={svm_poly_reg[-1].C}, \"\n",
        "          f\"epsilon={svm_poly_reg[-1].epsilon}\")\n",
        "plt.ylabel(\"$y$\", rotation=0)\n",
        "plt.grid()\n",
        "\n",
        "plt.sca(axes[1])\n",
        "plot_svm_regression(svm_poly_reg2, X, y, [-1, 1, 0, 1])\n",
        "plt.title(f\"degree={svm_poly_reg2[-1].degree}, \"\n",
        "          f\"C={svm_poly_reg2[-1].C}, \"\n",
        "          f\"epsilon={svm_poly_reg2[-1].epsilon}\")\n",
        "plt.grid()\n",
        "save_fig(\"svm_with_polynomial_kernel_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75-YKt32aRUb"
      },
      "source": [
        "# Under the hood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBGXqOA-aRUb"
      },
      "outputs": [],
      "source": [
        "# extra code â€“ this cell generates and saves Figure 5â€“12\n",
        "\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def plot_2D_decision_function(w, b, ylabel=True, x1_lim=[-3, 3]):\n",
        "    x1 = np.linspace(x1_lim[0], x1_lim[1], 200)\n",
        "    y = w * x1 + b\n",
        "    half_margin = 1 / w\n",
        "\n",
        "    plt.plot(x1, y, \"b-\", linewidth=2, label=r\"$s = w_1 x_1$\")\n",
        "    plt.axhline(y=0, color='k', linewidth=1)\n",
        "    plt.axvline(x=0, color='k', linewidth=1)\n",
        "    rect = patches.Rectangle((-half_margin, -2), 2 * half_margin, 4,\n",
        "                             edgecolor='none', facecolor='gray', alpha=0.2)\n",
        "    plt.gca().add_patch(rect)\n",
        "    plt.plot([-3, 3], [1, 1], \"k--\", linewidth=1)\n",
        "    plt.plot([-3, 3], [-1, -1], \"k--\", linewidth=1)\n",
        "    plt.plot(half_margin, 1, \"k.\")\n",
        "    plt.plot(-half_margin, -1, \"k.\")\n",
        "    plt.axis(x1_lim + [-2, 2])\n",
        "    plt.xlabel(\"$x_1$\")\n",
        "    if ylabel:\n",
        "        plt.ylabel(\"$s$\", rotation=0, labelpad=5)\n",
        "        plt.legend()\n",
        "        plt.text(1.02, -1.6, \"Margin\", ha=\"left\", va=\"center\", color=\"k\")\n",
        "\n",
        "    plt.annotate(\n",
        "        '', xy=(-half_margin, -1.6), xytext=(half_margin, -1.6),\n",
        "        arrowprops={'ec': 'k', 'arrowstyle': '<->', 'linewidth': 1.5}\n",
        "    )\n",
        "    plt.title(f\"$w_1 = {w}$\")\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(9, 3.2), sharey=True)\n",
        "plt.sca(axes[0])\n",
        "plot_2D_decision_function(1, 0)\n",
        "plt.grid()\n",
        "plt.sca(axes[1])\n",
        "plot_2D_decision_function(0.5, 0, ylabel=False)\n",
        "plt.grid()\n",
        "save_fig(\"small_w_large_margin_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TP2KCjzaRUb"
      },
      "outputs": [],
      "source": [
        "# extra code â€“ this cell generates and saves Figure 5â€“13\n",
        "\n",
        "s = np.linspace(-2.5, 2.5, 200)\n",
        "hinge_pos = np.where(1 - s < 0, 0, 1 - s)  # max(0, 1 - s)\n",
        "hinge_neg = np.where(1 + s < 0, 0, 1 + s)  # max(0, 1 + s)\n",
        "\n",
        "titles = (r\"Hinge loss = $max(0, 1 - s\\,t)$\", \"Squared Hinge loss\")\n",
        "\n",
        "fix, axs = plt.subplots(1, 2, sharey=True, figsize=(8.2, 3))\n",
        "\n",
        "for ax, loss_pos, loss_neg, title in zip(\n",
        "        axs, (hinge_pos, hinge_pos ** 2), (hinge_neg, hinge_neg ** 2), titles):\n",
        "    ax.plot(s, loss_pos, \"g-\", linewidth=2, zorder=10, label=\"$t=1$\")\n",
        "    ax.plot(s, loss_neg, \"r--\", linewidth=2, zorder=10, label=\"$t=-1$\")\n",
        "    ax.grid(True)\n",
        "    ax.axhline(y=0, color='k')\n",
        "    ax.axvline(x=0, color='k')\n",
        "    ax.set_xlabel(r\"$s = \\mathbf{w}^\\intercal \\mathbf{x} + b$\")\n",
        "    ax.axis([-2.5, 2.5, -0.5, 2.5])\n",
        "    ax.legend(loc=\"center right\")\n",
        "    ax.set_title(title)\n",
        "    ax.set_yticks(np.arange(0, 2.5, 1))\n",
        "    ax.set_aspect(\"equal\")\n",
        "\n",
        "save_fig(\"hinge_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUWmNjhJaRUc"
      },
      "source": [
        "# Extra Material"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBLyxocUaRUc"
      },
      "source": [
        "## Linear SVM classifier implementation using Batch Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDkmD95raRUc"
      },
      "outputs": [],
      "source": [
        "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
        "y = (iris.target == 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9onBsu0aRUc"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class MyLinearSVC(BaseEstimator):\n",
        "    def __init__(self, C=1, eta0=1, eta_d=10000, n_epochs=1000,\n",
        "                 random_state=None):\n",
        "        self.C = C\n",
        "        self.eta0 = eta0\n",
        "        self.n_epochs = n_epochs\n",
        "        self.random_state = random_state\n",
        "        self.eta_d = eta_d\n",
        "\n",
        "    def eta(self, epoch):\n",
        "        return self.eta0 / (epoch + self.eta_d)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Random initialization\n",
        "        if self.random_state:\n",
        "            np.random.seed(self.random_state)\n",
        "        w = np.random.randn(X.shape[1], 1)  # n feature weights\n",
        "        b = 0\n",
        "\n",
        "        t = np.array(y, dtype=np.float64).reshape(-1, 1) * 2 - 1\n",
        "        X_t = X * t\n",
        "        self.Js = []\n",
        "\n",
        "        # Training\n",
        "        for epoch in range(self.n_epochs):\n",
        "            support_vectors_idx = (X_t.dot(w) + t * b < 1).ravel()\n",
        "            X_t_sv = X_t[support_vectors_idx]\n",
        "            t_sv = t[support_vectors_idx]\n",
        "\n",
        "            J = 1/2 * (w * w).sum() + self.C * ((1 - X_t_sv.dot(w)).sum() - b * t_sv.sum())\n",
        "            self.Js.append(J)\n",
        "\n",
        "            w_gradient_vector = w - self.C * X_t_sv.sum(axis=0).reshape(-1, 1)\n",
        "            b_derivative = -self.C * t_sv.sum()\n",
        "\n",
        "            w = w - self.eta(epoch) * w_gradient_vector\n",
        "            b = b - self.eta(epoch) * b_derivative\n",
        "\n",
        "\n",
        "        self.intercept_ = np.array([b])\n",
        "        self.coef_ = np.array([w])\n",
        "        support_vectors_idx = (X_t.dot(w) + t * b < 1).ravel()\n",
        "        self.support_vectors_ = X[support_vectors_idx]\n",
        "        return self\n",
        "\n",
        "    def decision_function(self, X):\n",
        "        return X.dot(self.coef_[0]) + self.intercept_[0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.decision_function(X) >= 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZM4lIHmraRUc"
      },
      "outputs": [],
      "source": [
        "C = 2\n",
        "svm_clf = MyLinearSVC(C=C, eta0 = 10, eta_d = 1000, n_epochs=60000,\n",
        "                      random_state=2)\n",
        "svm_clf.fit(X, y)\n",
        "svm_clf.predict(np.array([[5, 2], [4, 1]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6n2b1SAaRUc"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(svm_clf.n_epochs), svm_clf.Js)\n",
        "plt.axis([0, svm_clf.n_epochs, 0, 100])\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuQXPNZZaRUc"
      },
      "outputs": [],
      "source": [
        "print(svm_clf.intercept_, svm_clf.coef_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SglOnS25aRUc"
      },
      "outputs": [],
      "source": [
        "svm_clf2 = SVC(kernel=\"linear\", C=C)\n",
        "svm_clf2.fit(X, y.ravel())\n",
        "print(svm_clf2.intercept_, svm_clf2.coef_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXdE6DuGaRUc"
      },
      "outputs": [],
      "source": [
        "yr = y.ravel()\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(11, 3.2), sharey=True)\n",
        "plt.sca(axes[0])\n",
        "plt.plot(X[:, 0][yr==1], X[:, 1][yr==1], \"g^\", label=\"Iris virginica\")\n",
        "plt.plot(X[:, 0][yr==0], X[:, 1][yr==0], \"bs\", label=\"Not Iris virginica\")\n",
        "plot_svc_decision_boundary(svm_clf, 4, 6)\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.ylabel(\"Petal width\")\n",
        "plt.title(\"MyLinearSVC\")\n",
        "plt.axis([4, 6, 0.8, 2.8])\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.grid()\n",
        "\n",
        "plt.sca(axes[1])\n",
        "plt.plot(X[:, 0][yr==1], X[:, 1][yr==1], \"g^\")\n",
        "plt.plot(X[:, 0][yr==0], X[:, 1][yr==0], \"bs\")\n",
        "plot_svc_decision_boundary(svm_clf2, 4, 6)\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.title(\"SVC\")\n",
        "plt.axis([4, 6, 0.8, 2.8])\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "1CO3z69AaRUd"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd_clf = SGDClassifier(loss=\"hinge\", alpha=0.017, max_iter=1000, tol=1e-3,\n",
        "                        random_state=42)\n",
        "sgd_clf.fit(X, y)\n",
        "\n",
        "m = len(X)\n",
        "t = np.array(y).reshape(-1, 1) * 2 - 1  # -1 if y == 0, or +1 if y == 1\n",
        "X_b = np.c_[np.ones((m, 1)), X]  # Add bias input x0=1\n",
        "X_b_t = X_b * t\n",
        "sgd_theta = np.r_[sgd_clf.intercept_[0], sgd_clf.coef_[0]]\n",
        "print(sgd_theta)\n",
        "support_vectors_idx = (X_b_t.dot(sgd_theta) < 1).ravel()\n",
        "sgd_clf.support_vectors_ = X[support_vectors_idx]\n",
        "sgd_clf.C = C\n",
        "\n",
        "plt.figure(figsize=(5.5, 3.2))\n",
        "plt.plot(X[:, 0][yr==1], X[:, 1][yr==1], \"g^\")\n",
        "plt.plot(X[:, 0][yr==0], X[:, 1][yr==0], \"bs\")\n",
        "plot_svc_decision_boundary(sgd_clf, 4, 6)\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.ylabel(\"Petal width\")\n",
        "plt.title(\"SGDClassifier\")\n",
        "plt.axis([4, 6, 0.8, 2.8])\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxMyW6TRaRUd"
      },
      "source": [
        "# Exercise solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT-UQAJfaRUd"
      },
      "source": [
        "## 1. to 8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9lwYitfaRUd"
      },
      "source": [
        "1. The fundamental idea behind Support Vector Machines is to fit the widest possible \"street\" between the classes. In other words, the goal is to have the largest possible margin between the decision boundary that separates the two classes and the training instances. When performing soft margin classification, the SVM searches for a compromise between perfectly separating the two classes and having the widest possible street (i.e., a few instances may end up on the street). Another key idea is to use kernels when training on nonlinear datasets. SVMs can also be tweaked to perform linear and nonlinear regression, as well as novelty detection.\n",
        "2. After training an SVM, a _support vector_ is any instance located on the \"street\" (see the previous answer), including its border. The decision boundary is entirely determined by the support vectors. Any instance that is _not_ a support vector (i.e., is off the street) has no influence whatsoever; you could remove them, add more instances, or move them around, and as long as they stay off the street they won't affect the decision boundary. Computing the predictions with a kernelized SVM only involves the support vectors, not the whole training set.\n",
        "3. SVMs try to fit the largest possible \"street\" between the classes (see the first answer), so if the training set is not scaled, the SVM will tend to neglect small features (see Figure 5â€“2).\n",
        "4. You can use the `decision_function()` method to get confidence scores. These scores represent the distance between the instance and the decision boundary. However, they cannot be directly converted into an estimation of the class probability. If you set `probability=True` when creating an `SVC`, then at the end of training it will use 5-fold cross-validation to generate out-of-sample scores for the training samples, and it will train a `LogisticRegression` model to map these scores to estimated probabilities. The `predict_proba()` and `predict_log_proba()` methods will then be available.\n",
        "5. All three classes can be used for large-margin linear classification. The `SVC` class also supports the kernel trick, which makes it capable of handling nonlinear tasks. However, this comes at a cost: the `SVC` class does not scale well to datasets with many instances. It does scale well to a large number of features, though. The `LinearSVC` class implements an optimized algorithm for linear SVMs, while `SGDClassifier` uses Stochastic Gradient Descent. Depending on the dataset `LinearSVC` may be a bit faster than `SGDClassifier`, but not always, and `SGDClassifier` is more flexible, plus it supports incremental learning.\n",
        "6. If an SVM classifier trained with an RBF kernel underfits the training set, there might be too much regularization. To decrease it, you need to increase `gamma` or `C` (or both).\n",
        "7. A Regression SVM model tries to fit as many instances within a small margin around its predictions. If you add instances within this margin, the model will not be affected at all: it is said to be _Ïµ-insensitive_.\n",
        "8. The kernel trick is mathematical technique that makes it possible to train a nonlinear SVM model. The resulting model is equivalent to mapping the inputs to another space using a nonlinear transformation, then training a linear SVM on the resulting high-dimensional inputs. The kernel trick gives the same result without having to transform the inputs at all."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg1A3ptfaRUd"
      },
      "source": [
        "# 9."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fH9I7j3aRUd"
      },
      "source": [
        "_Exercise: Train a `LinearSVC` on a linearly separable dataset. Then train an `SVC` and a `SGDClassifier` on the same dataset. See if you can get them to produce roughly the same model._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIsAQ2qeaRUd"
      },
      "source": [
        "Let's use the Iris dataset: the Iris Setosa and Iris Versicolor classes are linearly separable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOuSGkefaRUd"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris(as_frame=True)\n",
        "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
        "y = iris.target\n",
        "\n",
        "setosa_or_versicolor = (y == 0) | (y == 1)\n",
        "X = X[setosa_or_versicolor]\n",
        "y = y[setosa_or_versicolor]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG_t3iMbaRUd"
      },
      "source": [
        "Now let's build and train 3 models:\n",
        "* Remember that `LinearSVC` uses `loss=\"squared_hinge\"` by default, so if we want all 3 models to produce similar results, we need to set `loss=\"hinge\"`.\n",
        "* Also, the `SVC` class uses an RBF kernel by default, so we need to set `kernel=\"linear\"` to get similar results as the other two models.\n",
        "* Lastly, the `SGDClassifier` class does not have a `C` hyperparameter, but it has another regularization hyperparameter called `alpha`, so we can tweak it to get similar results as the other two models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTOeMgh3aRUd"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "C = 5\n",
        "alpha = 0.05\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "lin_clf = LinearSVC(loss=\"hinge\", C=C, random_state=42).fit(X_scaled, y)\n",
        "svc_clf = SVC(kernel=\"linear\", C=C).fit(X_scaled, y)\n",
        "sgd_clf = SGDClassifier(alpha=alpha, random_state=42).fit(X_scaled, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4p2vO-9aRUd"
      },
      "source": [
        "Let's plot the decision boundaries of these three models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgbp8anSaRUe"
      },
      "outputs": [],
      "source": [
        "def compute_decision_boundary(model):\n",
        "    w = -model.coef_[0, 0] / model.coef_[0, 1]\n",
        "    b = -model.intercept_[0] / model.coef_[0, 1]\n",
        "    return scaler.inverse_transform([[-10, -10 * w + b], [10, 10 * w + b]])\n",
        "\n",
        "lin_line = compute_decision_boundary(lin_clf)\n",
        "svc_line = compute_decision_boundary(svc_clf)\n",
        "sgd_line = compute_decision_boundary(sgd_clf)\n",
        "\n",
        "# Plot all three decision boundaries\n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.plot(lin_line[:, 0], lin_line[:, 1], \"k:\", label=\"LinearSVC\")\n",
        "plt.plot(svc_line[:, 0], svc_line[:, 1], \"b--\", linewidth=2, label=\"SVC\")\n",
        "plt.plot(sgd_line[:, 0], sgd_line[:, 1], \"r-\", label=\"SGDClassifier\")\n",
        "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\") # label=\"Iris versicolor\"\n",
        "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\") # label=\"Iris setosa\"\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.ylabel(\"Petal width\")\n",
        "plt.legend(loc=\"upper center\")\n",
        "plt.axis([0, 5.5, 0, 2])\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csmEmXXoaRUe"
      },
      "source": [
        "Close enough!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0o7vqZgaRUe"
      },
      "source": [
        "# 10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrhMS9gdaRUe"
      },
      "source": [
        "_Exercise: Train an SVM classifier on the Wine dataset, which you can load using `sklearn.datasets.load_wine()`. This dataset contains the chemical analysis of 178 wine samples produced by 3 different cultivators: the goal is to train a classification model capable of predicting the cultivator based on the wine's chemical analysis. Since SVM classifiers are binary classifiers, you will need to use one-versus-all to classify all 3 classes. What accuracy can you reach?_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qXM0Ex3aRUe"
      },
      "source": [
        "First, let's fetch the dataset, look at its description, then split it into a training set and a test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6AJzI16aRUe"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "\n",
        "wine = load_wine(as_frame=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pmaHhWSaRUe"
      },
      "outputs": [],
      "source": [
        "print(wine.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-v6D47WaRUe"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    wine.data, wine.target, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lLR_qyLaRUe"
      },
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgX7keZiaRUe"
      },
      "outputs": [],
      "source": [
        "y_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kagyCh2yaRUe"
      },
      "source": [
        "Let's start simple, with a linear SVM classifier. It will automatically use the One-vs-All (also called One-vs-the-Rest, OvR) strategy, so there's nothing special we need to do to handle multiple classes. Easy, right?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUg3G3ReaRUe"
      },
      "outputs": [],
      "source": [
        "lin_clf = LinearSVC(random_state=42)\n",
        "lin_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZfjiBjwaRUf"
      },
      "source": [
        "Oh no! It failed to converge. Can you guess why? Do you think we must just increase the number of training iterations? Let's see:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h23CIte7aRUf"
      },
      "outputs": [],
      "source": [
        "lin_clf = LinearSVC(max_iter=1_000_000, random_state=42)\n",
        "lin_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgXNeOV2aRUf"
      },
      "source": [
        "Even with one million iterations, it still did not converge. There must be another problem.\n",
        "\n",
        "Let's still evaluate this model with `cross_val_score`, it will serve as a baseline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uSl_v30aRUf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cross_val_score(lin_clf, X_train, y_train).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pfbh1dZaRUf"
      },
      "source": [
        "Well 91% accuracy on this dataset is not great. So did you guess what the problem is?\n",
        "\n",
        "That's right, we forgot to scale the features! Always remember to scale the features when using SVMs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRn7Vu1naRUf"
      },
      "outputs": [],
      "source": [
        "lin_clf = make_pipeline(StandardScaler(),\n",
        "                        LinearSVC(random_state=42))\n",
        "lin_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps1ngVFdaRUf"
      },
      "source": [
        "Now it converges without any problem. Let's measure its performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmXCXTkDaRUf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cross_val_score(lin_clf, X_train, y_train).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtnDXnNlaRUf"
      },
      "source": [
        "Nice! We get 97.7% accuracy, that's much better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylOV8PvGaRUf"
      },
      "source": [
        "Let's see if a kernelized SVM will do better. We will use a default `SVC` for now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lr04AjByaRUf"
      },
      "outputs": [],
      "source": [
        "svm_clf = make_pipeline(StandardScaler(), SVC(random_state=42))\n",
        "cross_val_score(svm_clf, X_train, y_train).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQWkqYgCaRUg"
      },
      "source": [
        "That's not better, but perhaps we need to do a bit of hyperparameter tuning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EapQiOZBaRUg"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import loguniform, uniform\n",
        "\n",
        "param_distrib = {\n",
        "    \"svc__gamma\": loguniform(0.001, 0.1),\n",
        "    \"svc__C\": uniform(1, 10)\n",
        "}\n",
        "rnd_search_cv = RandomizedSearchCV(svm_clf, param_distrib, n_iter=100, cv=5,\n",
        "                                   random_state=42)\n",
        "rnd_search_cv.fit(X_train, y_train)\n",
        "rnd_search_cv.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lg8rhDeBaRUg"
      },
      "outputs": [],
      "source": [
        "rnd_search_cv.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWNY5O62aRUg"
      },
      "source": [
        "Ah, this looks excellent! Let's select this model. Now we can test it on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN79onXkaRUg"
      },
      "outputs": [],
      "source": [
        "rnd_search_cv.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eejfjhQDaRUg"
      },
      "source": [
        "This tuned kernelized SVM performs better than the `LinearSVC` model, but we get a lower score on the test set than we measured using cross-validation. This is quite common: since we did so much hyperparameter tuning, we ended up slightly overfitting the cross-validation test sets. It's tempting to tweak the hyperparameters a bit more until we get a better result on the test set, but this would probably not help, as we would just start overfitting the test set. Anyway, this score is not bad at all, so let's stop here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FevDNLR8aRUg"
      },
      "source": [
        "## 11."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "812zdKhAaRUg"
      },
      "source": [
        "_Exercise: Train and fine-tune an SVM regressor on the California housing dataset. You can use the original dataset rather than the tweaked version we used in Chapter 2. The original dataset can be fetched using `sklearn.datasets.fetch_california_housing()`. The targets represent hundreds of thousands of dollars. Since there are over 20,000 instances, SVMs can be slow, so for hyperparameter tuning you should use much less instances (e.g., 2,000), to test many more hyperparameter combinations. What is your best model's RMSE?_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhlTqfqQaRUg"
      },
      "source": [
        "Let's load the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-2TM7S7aRUg"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGgESGolaRUg"
      },
      "source": [
        "Split it into a training set and a test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QzLDvH4aRUg"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2utGbb6iaRUg"
      },
      "source": [
        "Don't forget to scale the data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_kpM0pJaRUg"
      },
      "source": [
        "Let's train a simple `LinearSVR` first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEwD6UJyaRUh"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "\n",
        "lin_svr = make_pipeline(StandardScaler(), LinearSVR(random_state=42))\n",
        "lin_svr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT3bo46ZaRUh"
      },
      "source": [
        "It did not converge, so let's increase `max_iter`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qWRMrvraRUh"
      },
      "outputs": [],
      "source": [
        "lin_svr = make_pipeline(StandardScaler(),\n",
        "                        LinearSVR(max_iter=5000, random_state=42))\n",
        "lin_svr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6aYgpUmaRUh"
      },
      "source": [
        "Let's see how it performs on the training set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMb2vQiqaRUh"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "y_pred = lin_svr.predict(X_train)\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "mse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IQYBI9vaRUh"
      },
      "source": [
        "Let's look at the RMSE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ry7Gpd7OaRUh"
      },
      "outputs": [],
      "source": [
        "np.sqrt(mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek-BgJcwaRUh"
      },
      "source": [
        "In this dataset, the targets represent hundreds of thousands of dollars. The RMSE gives a rough idea of the kind of error you should expect (with a higher weight for large errors): so with this model we can expect errors close to $98,000! Not great. Let's see if we can do better with an RBF Kernel. We will use randomized search with cross validation to find the appropriate hyperparameter values for `C` and `gamma`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpIv0oPlaRUh"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import loguniform, uniform\n",
        "\n",
        "svm_clf = make_pipeline(StandardScaler(), SVR())\n",
        "\n",
        "param_distrib = {\n",
        "    \"svr__gamma\": loguniform(0.001, 0.1),\n",
        "    \"svr__C\": uniform(1, 10)\n",
        "}\n",
        "rnd_search_cv = RandomizedSearchCV(svm_clf, param_distrib,\n",
        "                                   n_iter=100, cv=3, random_state=42)\n",
        "rnd_search_cv.fit(X_train[:2000], y_train[:2000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi0_krYlaRUh"
      },
      "outputs": [],
      "source": [
        "rnd_search_cv.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7fYPWf5aRUh"
      },
      "outputs": [],
      "source": [
        "-cross_val_score(rnd_search_cv.best_estimator_, X_train, y_train,\n",
        "                 scoring=\"neg_root_mean_squared_error\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa9vopkjaRUh"
      },
      "source": [
        "Looks much better than the linear model. Let's select this model and evaluate it on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYyTy_P1aRUi"
      },
      "outputs": [],
      "source": [
        "y_pred = rnd_search_cv.best_estimator_.predict(X_test)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMRFcxvRaRUi"
      },
      "source": [
        "So SVMs worked very well on the Wine dataset, but not so much on the California Housing dataset. In Chapter 2, we found that Random Forests worked better for that dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sslomvOgaRUi"
      },
      "source": [
        "And that's all for today!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULCWrmv4aRUi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}